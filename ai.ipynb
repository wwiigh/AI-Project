{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyOUTcxSEI52qwC66U0Y+knJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wwiigh/AI-Project/blob/dataset2/ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xQ67hzhaQuJ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12a27a77-47ec-43fb-dd29-07353f4280db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'AI-Project'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 21 (delta 2), reused 9 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (21/21), 671.89 KiB | 7.38 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "/content/AI-Project\n",
            "now branch\n",
            "* \u001b[32mmain\u001b[m\n",
            "\n",
            "total branch\n",
            "* \u001b[32mmain\u001b[m\n",
            "  \u001b[31mremotes/origin/HEAD\u001b[m -> origin/main\n",
            "  \u001b[31mremotes/origin/dataset1\u001b[m\n",
            "  \u001b[31mremotes/origin/dataset2\u001b[m\n",
            "  \u001b[31mremotes/origin/main\u001b[m\n",
            "  \u001b[31mremotes/origin/question1\u001b[m\n",
            "  \u001b[31mremotes/origin/question2\u001b[m\n",
            "\n",
            "change from main to dataset2\n",
            "Branch 'dataset2' set up to track remote branch 'dataset2' from 'origin'.\n",
            "Switched to a new branch 'dataset2'\n",
            "* \u001b[32mdataset2\u001b[m\n",
            "  main\u001b[m\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/wwiigh/AI-Project.git\n",
        "%cd /content/AI-Project\n",
        "print(\"now branch\")\n",
        "!git branch\n",
        "print(\"\\ntotal branch\")\n",
        "!git branch -a\n",
        "print(\"\\nchange from main to dataset2\")\n",
        "!git checkout dataset2\n",
        "!git branch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python process.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GlzEN-3T9BF",
        "outputId": "8067798c-e4d8-4638-98d5-bed4ff4994ae"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    Title:\\nNo-Bake Nut Cookies\\n\\nIngredients:\\n1...\n",
            "1    Title:\\nJewell Ball'S Chicken\\n\\nIngredients:\\...\n",
            "2    Title:\\nCreamy Corn\\n\\nIngredients:\\n2 (16 oz....\n",
            "3    Title:\\nChicken Funny\\n\\nIngredients:\\n1 large...\n",
            "4    Title:\\nReeses Cups(Candy)  \\n\\nIngredients:\\n...\n",
            "Name: full_recipe, dtype: object\n",
            "Title:\n",
            "No-Bake Nut Cookies\n",
            "\n",
            "Ingredients:\n",
            "1 c. firmly packed brown sugar\n",
            "1/2 c. evaporated milk\n",
            "1/2 tsp. vanilla\n",
            "1/2 c. broken nuts (pecans)\n",
            "2 tbsp. butter or margarine\n",
            "3 1/2 c. bite size shredded rice biscuits\n",
            "\n",
            "Directions:\n",
            "in a heavy 2-quart saucepan, mix brown sugar, nuts, evaporated milk and butter or margarine.\n",
            "stir over medium heat until mixture bubbles all over top.\n",
            "boil and stir 5 minutes more. take off heat.\n",
            "stir in vanilla and cereal; mix well.\n",
            "using 2 teaspoons, drop and shape into 30 clusters on wax paper.\n",
            "let stand until firm, about 30 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9-nUxKAUZuc",
        "outputId": "6ae22709-0d33-49e0-9577-15155e250476"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/297.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m163.8/297.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.29.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND2qDG8OUCzM",
        "outputId": "3e3309c9-60c8-4b22-a863-f684b1f8041b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-22 17:36:11.313370: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-22 17:36:11.313423: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-22 17:36:11.314794: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-22 17:36:12.525136: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n",
            " 21% 249/1210 [00:16<00:59, 16.10it/s]\n",
            "  0% 0/13 [00:00<?, ?it/s]\u001b[A\n",
            " 46% 6/13 [00:00<00:00, 49.91it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 2.0079548358917236, 'eval_runtime': 0.3687, 'eval_samples_per_second': 282.055, 'eval_steps_per_second': 35.257, 'epoch': 1.03}\n",
            " 21% 250/1210 [00:16<00:59, 16.10it/s]\n",
            "100% 13/13 [00:00<00:00, 40.62it/s]\u001b[A\n",
            "{'loss': 2.1284, 'grad_norm': 6.65800666809082, 'learning_rate': 2.9338842975206616e-05, 'epoch': 2.07}\n",
            " 41% 500/1210 [00:33<00:43, 16.38it/s]\n",
            "  0% 0/13 [00:00<?, ?it/s]\u001b[A\n",
            " 38% 5/13 [00:00<00:00, 45.84it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 1.9526448249816895, 'eval_runtime': 0.359, 'eval_samples_per_second': 289.728, 'eval_steps_per_second': 36.216, 'epoch': 2.07}\n",
            " 41% 500/1210 [00:33<00:43, 16.38it/s]\n",
            "100% 13/13 [00:00<00:00, 39.59it/s]\u001b[A\n",
            " 62% 749/1210 [00:49<00:33, 13.95it/s]\n",
            "  0% 0/13 [00:00<?, ?it/s]\u001b[A\n",
            " 38% 5/13 [00:00<00:00, 43.33it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 1.9305038452148438, 'eval_runtime': 0.3714, 'eval_samples_per_second': 280.044, 'eval_steps_per_second': 35.006, 'epoch': 3.1}\n",
            " 62% 750/1210 [00:49<00:32, 13.95it/s]\n",
            "100% 13/13 [00:00<00:00, 39.97it/s]\u001b[A\n",
            "{'loss': 1.8303, 'grad_norm': 6.369448184967041, 'learning_rate': 8.677685950413224e-06, 'epoch': 4.13}\n",
            " 83% 1000/1210 [01:05<00:13, 16.02it/s]\n",
            "  0% 0/13 [00:00<?, ?it/s]\u001b[A\n",
            " 38% 5/13 [00:00<00:00, 45.45it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 1.9215590953826904, 'eval_runtime': 0.3618, 'eval_samples_per_second': 287.465, 'eval_steps_per_second': 35.933, 'epoch': 4.13}\n",
            " 83% 1000/1210 [01:05<00:13, 16.02it/s]\n",
            "100% 13/13 [00:00<00:00, 39.47it/s]\u001b[A\n",
            "                                   \u001b[ACheckpoint destination directory ./results/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "100% 1209/1210 [01:29<00:00, 16.10it/s]There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n",
            "{'train_runtime': 89.9247, 'train_samples_per_second': 53.712, 'train_steps_per_second': 13.456, 'train_loss': 1.9393688359536416, 'epoch': 5.0}\n",
            "100% 1210/1210 [01:29<00:00, 13.46it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOZnjrzTaOyk",
        "outputId": "08d63c2b-3624-49ab-bdc7-dc656846a8d5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-22 17:42:23.591672: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-22 17:42:23.591729: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-22 17:42:23.593079: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-22 17:42:25.126609: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Title:\n",
            "chocolate cake\n",
            "\n",
            "Ingredients:\n",
            "1/2 c. butter or margarine\n",
            "1/2 c. flour\n",
            "8 eggs\n",
            "1 c. cocoa\n",
            "1 tsp. baking powder\n",
            "3 tbsp. oleo or cocoa dissolved in warm water\n",
            "1/2 c. sugar\n",
            "1/4 c. vanilla or cool whip\n",
            "salt and pepper to taste added to taste\n",
            "\n",
            "Directions:\n",
            "cream butter and margarine. gradually add flour and eggs, beating well after each addition.\n",
            "add cocoa and beat well after each addition.\n",
            "mix well and set aside.\n",
            "add 1 container instant vanilla pudding to pudding mix.\n",
            "add 2 eggs and beat well after each addition.\n",
            "pour into 2 greased and floured 9 x 13-inch pan. bake at 325Â° until tender.\n",
            "yields 3 to 4 dozen.\n",
            "Title:\n",
            "Chocolate-Onion Bread(Double Cake(Double Cake)  \n",
            "\n",
            "Ingredients:\n",
            "\n"
          ]
        }
      ]
    }
  ]
}